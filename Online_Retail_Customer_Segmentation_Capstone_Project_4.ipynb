{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aramnani/Capstone-Project---4---Online-Retail-Customer-Segmentation/blob/main/Online_Retail_Customer_Segmentation_Capstone_Project_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name -** Aakash Ramnani\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, the task is to indentify major customer segments on a traditional data set which contains all the transaction occuring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store retail.\n",
        "\n",
        "Project is performed in following steps\n",
        "\n",
        "1. **Basic EDA on Dataset -**  This step involves exploring data set and checking relationship between variables and checking their distributions.\n",
        "\n",
        "2. **RFM Analysis -** RFM (Recency, Frequency, Monetary) analysis is a customer segmentation technique that uses past purchase behavior to divide customers into groups.\n",
        "\n",
        "  - **RECENCY (R):** Days since last purchase\n",
        "  - **FREQUENCY (F):** Total number of purchases\n",
        "  - **MONETARY VALUE (M):** Total money this customer spent.\n",
        "\n",
        "3. **Visualization Using different Charts -** This step involves creating various charts and graphs to visualize the data and identify the patterns and relationships among the features. Some of the charts that can be used are bar charts, scatter plots, heat maps, etc.\n",
        "\n",
        "4. **Hypothesis Testing -** This step involves testing some hypotheses or assumptions about the data using statistical methods.\n",
        "\n",
        "5. **Feature Engineering for clustering -** This step involves creating new features or transforming existing features to make them suitable for clustering.\n",
        "\n",
        "6. **Clustering analysis using k-means and agglomerative -** This step involves applying k-means and agglomerative clustering algorithms to group the customers based on their RFM score. This step can help to identify the optimal segments of customers."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this project, your task is to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time, warnings\n",
        "import datetime as dt\n",
        "\n",
        "#modules for predictive models\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import scipy.stats as stats\n",
        "\n",
        "#visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qJHF8WADskMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Almabetter/machine learning/project/unsupervised/Online Retail.xlsx - Online Retail.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.tail()"
      ],
      "metadata": {
        "id": "NXQT6beltJVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"No. of rows in dataset are : \", dataset.shape[0])\n",
        "print(\"No. of columns in dataset are : \", dataset.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "dataset.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(dataset.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- No. of rows in dataset are :  541909\n",
        "- No. of columns in dataset are :  8\n",
        "- There are missing values in Description and CustomerID column."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **InvoiceNo:** Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "- **StockCode:** Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "- **Description:** Product (item) name. Nominal.\n",
        "- **Quantity:** The quantities of each product (item) per transaction. Numeric.\n",
        "- **InvoiceDate:** Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "- **UnitPrice:** Unit price. Numeric, Product price per unit in sterling.\n",
        "- **CustomerID:** Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "- **Country:** Country name. Nominal, the name of the country where each customer resides."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in dataset.columns:\n",
        "  print(f\"Unique value for {col} : \", dataset[col].unique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of unique value for each variable\n",
        "uni_df = pd.DataFrame()\n",
        "uni_df['variables'] = dataset.columns.to_list()\n",
        "uni_df['unique values'] = uni_df['variables'].apply(lambda x : dataset[x].nunique())\n",
        "uni_df"
      ],
      "metadata": {
        "id": "b8uYcjOju5pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df1 = dataset.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values\n",
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "wf55ZZwTvBIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are missing values in CustomerID and Description.\n",
        "- The reason behind this could that customer buying from the online store was not a registered customer.\n",
        "- And there is no way we can impute the CustomerID and Description as CustomerID is unique to every customer and Description is unique to every product. So we will drop all the information with missing values."
      ],
      "metadata": {
        "id": "EibvpFtHvIS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "4V_aOHcgvFzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "RE0hzS8NvUmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of our dataframe after dropping missing values\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "F5SjpFf7vXjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "m8Sx6346vcwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changeing the datatype of InvoiceNo\n",
        "df1['InvoiceNo'] = df1['InvoiceNo'].astype('str')"
      ],
      "metadata": {
        "id": "y0Dx_wstvg52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoice Starting with C are cancellation invoice.\n",
        "# Dropping all the invoice starting with C.\n",
        "df1 = df1[~df1['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "sdW0wgNHvi_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of our dataframe after dropping cancellation invoice\n",
        "df1.shape"
      ],
      "metadata": {
        "id": "_4xTuGkUvoKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the datatype of InvoiceDate to datetime datatype\n",
        "# Checking for oldest and latest date\n",
        "df1[\"InvoiceDate\"] = pd.to_datetime(df1[\"InvoiceDate\"])\n",
        "print(\"Minimum Invoice Date\", min(df1[\"InvoiceDate\"]))\n",
        "print(\"Maximum Invoice Date\", max(df1[\"InvoiceDate\"]))"
      ],
      "metadata": {
        "id": "Gz-3AtC6v3Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for unit price\n",
        "print(\"Minimum UnitPrice\", min(df1[\"UnitPrice\"]))\n",
        "print(\"Maximum UnitPrice\", max(df1[\"UnitPrice\"]))\n",
        "df1[\"UnitPrice\"].describe()"
      ],
      "metadata": {
        "id": "NflDeXalv-i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There are observations with unit price 0.\n",
        "- We will be considering only those observation with unit price greater than 0."
      ],
      "metadata": {
        "id": "u7G1bYukwGQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Droping the observations with unit price 0\n",
        "df1 = df1[df1.UnitPrice > 0]\n",
        "df1[\"UnitPrice\"].describe()"
      ],
      "metadata": {
        "id": "RW7Wb7tywELm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for Quantity\n",
        "print(\"Minimum Quantity\", min(df1[\"Quantity\"]))\n",
        "print(\"Maximum Quantity\", max(df1[\"Quantity\"]))\n",
        "df1[\"Quantity\"].describe()"
      ],
      "metadata": {
        "id": "eCz4M-NywPX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the new column to the dataset Total_Amount\n",
        "df1[\"Total_sales\"] = df1[\"UnitPrice\"]*df1[\"Quantity\"]"
      ],
      "metadata": {
        "id": "hWA2yc5wwT1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(1)"
      ],
      "metadata": {
        "id": "rE-mxE-UwWjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There is no way we can impute the CustomerID and Description as CustomerID is unique to every customer and Description is unique to every product. So we will drop all the information with missing values.\n",
        "- Changed the datatype of InvoiceNo.\n",
        "- Dropped all the invoice starting with C(Cancellation Invoice).\n",
        "- Changed the datatype of InvoiceDate to datetime datatype.\n",
        "- There are observations with unit price 0.\n",
        "- Dropped the observations with unit price 0.\n",
        "- Added the new column to the dataset Total_Amount using UnitPrice and Quantity."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA (Exploratory Data Analysis)**"
      ],
      "metadata": {
        "id": "AQfFYswWxnzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df1.copy()"
      ],
      "metadata": {
        "id": "kdXrAhiVx06J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "WKvI1zG6x8cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customer and sales analysis with respect to the country.\n",
        "# Unique Customer count and percentage with respect to the country.\n",
        "country_df = df.groupby(\"Country\")[\"CustomerID\"].nunique().reset_index().rename(columns = {\"CustomerID\":\"count_CustomerID\"})\n",
        "country_df[\"customer_%\"] = round(country_df[\"count_CustomerID\"]*100/country_df[\"count_CustomerID\"].sum(),2)\n",
        "country_df"
      ],
      "metadata": {
        "id": "USwTmBodyBYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total sales count and percentage with respect to the country.\n",
        "country_sales_df = df.groupby(\"Country\")[\"Total_sales\"].sum().reset_index()\n",
        "country_sales_df[\"Total_sales%\"] = round(country_sales_df[\"Total_sales\"]*100/country_sales_df[\"Total_sales\"].sum(),2)"
      ],
      "metadata": {
        "id": "Di2xsjbkyLvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_sales_df"
      ],
      "metadata": {
        "id": "Gkowgo32yOW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 90% of total customers are from United Kingdom and 82% of total sales is from United Kingdom.\n",
        "- So we will be only considering the observations corresponding to United Kingdom."
      ],
      "metadata": {
        "id": "Isj2_lGoyTSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.Country == 'United Kingdom']\n",
        "df['Country'].unique()"
      ],
      "metadata": {
        "id": "lkO2S34NybFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most Ordered Product\n",
        "most_ordered = df.groupby(['StockCode','Description'], as_index= False)['Quantity'].sum().sort_values(by='Quantity', ascending=False)\n",
        "most_ordered.head(5)"
      ],
      "metadata": {
        "id": "_R6xSHmOyhRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new feature from InvoiceDate\n",
        "df['Month']=df['InvoiceDate'].dt.month_name()\n",
        "df['Day']=df['InvoiceDate'].dt.day_name()\n",
        "df['Hour']=df['InvoiceDate'].dt.hour"
      ],
      "metadata": {
        "id": "k9linsaCzS3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly Transaction\n",
        "month_df=df['Month'].value_counts().reset_index()\n",
        "month_df.rename(columns={'index': 'Month_Name'}, inplace=True)\n",
        "month_df.rename(columns={'Month': 'Count'}, inplace=True)\n",
        "month_df"
      ],
      "metadata": {
        "id": "XS-ZBfyxzVbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Highest number of transactions are seen in month of November followed by October and December."
      ],
      "metadata": {
        "id": "klXu7VwAzZb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Day-wise Transaction\n",
        "day_df=df['Day'].value_counts().reset_index()\n",
        "day_df.rename(columns={'index': 'Days'}, inplace=True)\n",
        "day_df.rename(columns={'Day': 'Count'}, inplace=True)\n",
        "day_df"
      ],
      "metadata": {
        "id": "kv3yfd3zzjDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Highest transaction are seen on thursday.\n",
        "- There are no transaction on saturday."
      ],
      "metadata": {
        "id": "_nQsn5E8zmW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking what time of the day customer transact the most.\n",
        "hour_df=df['Hour'].value_counts().reset_index()\n",
        "hour_df.rename(columns={'index': 'Hours'}, inplace=True)\n",
        "hour_df.rename(columns={'Hour': 'Count'}, inplace=True)\n",
        "hour_df"
      ],
      "metadata": {
        "id": "KQ3HoKFizpjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **RFM(Recency,Frequency,Monetary) Model**"
      ],
      "metadata": {
        "id": "NWxFxCYKz_Qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RFM (Recency, Frequency, Monetary) analysis is a customer segmentation technique that uses past purchase behavior to divide customers into groups.\n",
        "\n",
        "- RFM helps divide customers into various categories or clusters to identify customers who are more likely to respond to promotions and also for future personalization services.\n",
        "\n",
        "  - RECENCY (R): Days since last purchase\n",
        "  - FREQUENCY (F): Total number of purchases\n",
        "  - MONETARY VALUE (M): Total money this customer spent."
      ],
      "metadata": {
        "id": "l2-4hYte0EqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recency**\n",
        "\n",
        "- To create a Recency feature variable, we need to decide the reference date for analysis and we wil define the reference date as one day before the last transaction."
      ],
      "metadata": {
        "id": "FenfGu2D0Mk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#last date available in our dataset\n",
        "df['InvoiceDate'].max()"
      ],
      "metadata": {
        "id": "7JXKnRNtz8tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest_date = dt.date(2011,12,9)\n",
        "print(latest_date)"
      ],
      "metadata": {
        "id": "UwW8wJLg0XAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new column called date which contains the date of invoice only\n",
        "df['date'] = df['InvoiceDate'].dt.date"
      ],
      "metadata": {
        "id": "LPjXNmou0abP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LPCa0-4n0mxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking last of purchase\n",
        "recency_df = df.groupby(by='CustomerID', as_index=False)['date'].max()\n",
        "recency_df.columns = ['CustomerID','LastPurshaceDate']\n",
        "recency_df.head()"
      ],
      "metadata": {
        "id": "qeWW3uqq0rH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating Recency\n",
        "recency_df['Recency'] = recency_df['LastPurshaceDate'].apply(lambda x: (latest_date - x).days)\n",
        "recency_df.head()"
      ],
      "metadata": {
        "id": "aDYSUop60wb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#droping LastPurchaseDate\n",
        "recency_df.drop('LastPurshaceDate', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZnnNYA9S00yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency**\n",
        "\n",
        "- Frequency helps us to know how many times a customer purchased from us. To do that we need to check how many invoices are registered by the same customer."
      ],
      "metadata": {
        "id": "jmz8RlXb06Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates\n",
        "df2 = df.copy()\n",
        "df2.drop_duplicates(subset=['InvoiceNo', 'CustomerID'], keep=\"first\", inplace=True)"
      ],
      "metadata": {
        "id": "e5R6NabV1BYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate frequency of purchases\n",
        "frequency_df = df2.groupby(by=['CustomerID'], as_index=False)['InvoiceNo'].count()\n",
        "frequency_df.columns = ['CustomerID','Frequency']\n",
        "frequency_df.head()"
      ],
      "metadata": {
        "id": "VLxh5O6g1Gya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monetary Value**\n",
        "\n",
        "Monetary attribute answers the question: How much money did the customer spent over time?"
      ],
      "metadata": {
        "id": "JyEN2WkU1Lhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monetary_df = df.groupby(by='CustomerID',as_index=False).agg({'Total_sales': 'sum'})\n",
        "monetary_df.columns = ['CustomerID','Monetary_Value']\n",
        "monetary_df.head()"
      ],
      "metadata": {
        "id": "VzA-JJpr2IbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating RFM table\n",
        "# Merging recency_df and frequency_df\n",
        "df3 = recency_df.merge(frequency_df,on='CustomerID')\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "y_UFY8R62Xky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging df3 and monetary_df\n",
        "rfm_df = df3.merge(monetary_df, on='CustomerID')\n",
        "# Use CustomerID as index\n",
        "rfm_df.set_index('CustomerID', inplace=True)\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "CycJ_xve2cGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Calculating RFM Score**"
      ],
      "metadata": {
        "id": "hvPVAh492eqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Quartiles to divide customer segments from RFM model\n",
        "quantiles = rfm_df.quantile(q=[0.25,0.5,0.75])\n",
        "quantiles"
      ],
      "metadata": {
        "id": "7JkX4tCQ2l4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into dictionary\n",
        "quantiles.to_dict()"
      ],
      "metadata": {
        "id": "6TrvBvwH2oxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating 2 funtions since according to quartiles high recency is bad while high frequency and monetory value is good.\n",
        "def RScore(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 4\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 3\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def FMScore(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 1\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 2\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4"
      ],
      "metadata": {
        "id": "qZbM98Dc2ry_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating R_score, F_score and M_score\n",
        "rfm_segmentation = rfm_df.copy()\n",
        "rfm_segmentation['R_Quartile'] = rfm_segmentation['Recency'].apply(RScore, args=('Recency',quantiles,))\n",
        "rfm_segmentation['F_Quartile'] = rfm_segmentation['Frequency'].apply(FMScore, args=('Frequency',quantiles,))\n",
        "rfm_segmentation['M_Quartile'] = rfm_segmentation['Monetary_Value'].apply(FMScore, args=('Monetary_Value',quantiles,))\n",
        "rfm_segmentation.head()"
      ],
      "metadata": {
        "id": "I0BGT_2m2uyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We assign a score from 1 to 4 to Recency, Frequency and Monetary. Four is the best/highest value, and one is the lowest/worst value."
      ],
      "metadata": {
        "id": "aaBhBXOx2za_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combinig R_Quartile, F_Quartile and M_Quartile\n",
        "rfm_segmentation['RFM'] = rfm_segmentation.R_Quartile.map(str) \\\n",
        "                            + rfm_segmentation.F_Quartile.map(str) \\\n",
        "                            + rfm_segmentation.M_Quartile.map(str)\n",
        "rfm_segmentation.head()"
      ],
      "metadata": {
        "id": "kKy1HYGv21mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating RMF score\n",
        "rfm_segmentation['RFMScore'] = rfm_segmentation[['R_Quartile', 'F_Quartile', 'M_Quartile']].sum(axis = 1)\n",
        "rfm_segmentation.head()"
      ],
      "metadata": {
        "id": "2nvk2NOa27LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the mean value for Recency, Frequency and Monetary corresponding to each score\n",
        "rfm_segmentation.groupby(\"RFMScore\")[['Recency','Frequency', 'Monetary_Value']].mean()"
      ],
      "metadata": {
        "id": "DuCBqbIp2-bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Customer with low recency value has high frequency and monetory value and vice a versa is true as well."
      ],
      "metadata": {
        "id": "3C1K2cua3CYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking our best customer with high frequency score\n",
        "rfm_segmentation[rfm_segmentation['RFMScore'] == 12].sort_values('Monetary_Value', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "-buugk2W3B9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RFM Segmentation**"
      ],
      "metadata": {
        "id": "GEjixV1fCsdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_segment = rfm_segmentation.copy()\n",
        "rfm_segment.reset_index(inplace=True)\n",
        "import itertools\n",
        "\n",
        "# Highest frequency as well as monetary value with least recency\n",
        "platinum_customers = ['444', '443']\n",
        "print (\"Platinum Customers                     : {}\".format(platinum_customers))\n",
        "\n",
        "# Get all combinations of [1, 2, 3,4] and length 2\n",
        "big_spenders_comb =  itertools.product([1, 2, 3,4],repeat = 2)\n",
        "\n",
        "# Print the obtained combinations\n",
        "big_spenders = []\n",
        "for i in list(big_spenders_comb):\n",
        "    item = (list(i))\n",
        "    item.append(4)\n",
        "    big_spenders.append( (\"\".join(map(str,item))))\n",
        "print (\"Big Spenders                           : {}\".format(big_spenders))\n",
        "\n",
        "#High-spending New Customers â€“ This group consists of those customers in 1-4-1 and 1-4-2.\n",
        "#These are customers who transacted only once, but very recently and they spent a lot\n",
        "\n",
        "high_spend_new_customers = ['413', '314' ,'313','414']\n",
        "print (\"High Spend New Customers               : {}\".format(high_spend_new_customers))\n",
        "\n",
        "\n",
        "lowest_spending_active_loyal_customers_comb =  itertools.product([ 3,4], repeat = 2)\n",
        "lowest_spending_active_loyal_customers = []\n",
        "for i in list(lowest_spending_active_loyal_customers_comb):\n",
        "    item = (list(i))\n",
        "    item.append(1)\n",
        "    lowest_spending_active_loyal_customers.append( (\"\".join(map(str,item))))\n",
        "print (\"Lowest Spending Active Loyal Customers : {}\".format(lowest_spending_active_loyal_customers))\n",
        "\n",
        "recent_customers_comb =  itertools.product([ 2,3,4], repeat = 2)\n",
        "recent_customers = []\n",
        "for i in list(recent_customers_comb):\n",
        "    item = (list(i))\n",
        "    item.insert(0,4)\n",
        "    recent_customers.append( (\"\".join(map(str,item))))\n",
        "print (\"Recent Customers                       : {}\".format(recent_customers))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "almost_lost = ['244', '234', '243', '233']        #  Low R - Customers are shopping less often now who used to shop a lot\n",
        "print (\"Good Customers Almost Lost             : {}\".format(almost_lost))\n",
        "\n",
        "churned_best_customers = ['144', '134' ,'143','133']\n",
        "print (\"Churned Best Customers                 : {}\".format(churned_best_customers))\n",
        "\n",
        "\n",
        "lost_cheap_customers = ['122','111' ,'121','112','221','212' ,'211'] # Customers shopped long ago but with less frequency and monetary value\n",
        "print (\"Lost Cheap Customers                   : {}\".format(lost_cheap_customers))"
      ],
      "metadata": {
        "id": "icvJ_-t-BDIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary for each segment to map them against each customer\n",
        "segment_dict = {\n",
        "    'Platinum Customers':platinum_customers,\n",
        "    'Big Spenders':      big_spenders,\n",
        "    'High Spend New Customers':high_spend_new_customers,\n",
        "    'Lowest-Spending Active Loyal Customers' : lowest_spending_active_loyal_customers ,\n",
        "    'Recent Customers': recent_customers,\n",
        "    'Good Customers Almost Lost':almost_lost,\n",
        "    'Churned Best Customers':   churned_best_customers,\n",
        "    'Lost Cheap Customers ': lost_cheap_customers,\n",
        "}"
      ],
      "metadata": {
        "id": "OZnN6CVqAmHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allocate segments to each customer as per the RFM score mapping\n",
        "def find_key(value):\n",
        "    for k, v in segment_dict.items():\n",
        "        if value in v:\n",
        "            return k\n",
        "rfm_segment['Segment'] = rfm_segment.RFM.map(find_key)\n",
        "\n",
        "# Allocate all remaining customers to others segment category\n",
        "rfm_segment.Segment.fillna('others', inplace=True)\n",
        "rfm_segment.sample(10)"
      ],
      "metadata": {
        "id": "znPCRM20Bnj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now that we know our customers segments we can choose how to target or deal with each segment."
      ],
      "metadata": {
        "id": "_mvmO40y3NWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Unique Customer count and percentage with respect to the country.\n",
        "country_df1 = df1.groupby(\"Country\")[\"CustomerID\"].nunique().reset_index().rename(columns = {\"CustomerID\":\"count_CustomerID\"})\n",
        "country_df1[\"customer_%\"] = round(country_df1[\"count_CustomerID\"]*100/country_df1[\"count_CustomerID\"].sum(),2)\n",
        "\n",
        "# Visualizing for country vs customer percentage\n",
        "country_df1 = country_df1.sort_values(by = \"customer_%\", ascending = False)\n",
        "fig, ax = plt.subplots(figsize=(10,4),dpi=100)\n",
        "ax=sns.barplot(x=country_df1[\"Country\"], y=country_df1['customer_%'])\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=50, ha=\"right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used barplot to show the percentage count of customer with respect to country."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "90% of total customer are from United-Kingdom."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The store is UK based so we can expect that more number of customer will be from United Kingdom."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Total sales count and percentage with respect to the country.\n",
        "country_sales_df1 = df1.groupby(\"Country\")[\"Total_sales\"].sum().reset_index()\n",
        "country_sales_df1[\"Total_sales%\"] = round(country_sales_df1[\"Total_sales\"]*100/country_sales_df1[\"Total_sales\"].sum(),2)\n",
        "\n",
        "# Visualizing for country vs total sales percentage\n",
        "country_sales_df1 = country_sales_df1.sort_values(by = \"Total_sales%\", ascending = False)\n",
        "fig, ax = plt.subplots(figsize=(10,4),dpi=100)\n",
        "ax=sns.barplot(x=country_sales_df1[\"Country\"], y=country_sales_df1['Total_sales%'])\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=50, ha=\"right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used barplot to show the percentage count of total sales with respect to country."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "82% of total sales revenue is from United Kingdom."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we learnt that almost 90% of total customers are from United Kingdom, this leads to 82% of total sales revenue coming from United Kingdom."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#Visualizing top 5 product name\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Top 5 Product Name')\n",
        "sns.barplot(x = 'Quantity', y = 'Description', data = most_ordered[:5], palette = 'spring_r')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used barplot to comapre the Description with respect to Quantity to come up with top 5 most ordered products."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paper Craft,little birdie and Medium Ceramic top storage jar are the top 2 products that are ordered the most."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight helps the store to understand the demand of a pirticular product so that they can keep the stock intact and reduce that their purchase price by buying in quantity as they are sure about the fact that it is one of the most ordered product."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Visualising monthly transaction\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Month wise transaction')\n",
        "sns.barplot(x = 'Month_Name' ,y = 'Count', data = month_df, palette = 'spring_r')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Bar plot to show the transaction count per month."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most Number of transactions are done in the month of November followed by October and December."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These behaviour can be expected because of festive season in those month. This insight can help store to be prepared for all sales by keeping stock intact and also running promotion accordingly to drive more sales."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Visualizing for day-wise transaction\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Day wise transaction')\n",
        "sns.barplot(x = 'Days', y = 'Count', data = day_df, palette = 'spring_r')"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Bar plot to show the transaction count per day of the week."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Highest transaction are seen on thursday.\n",
        "- There are no transaction on saturday."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no sales on saturday store should look into it and figure out the reason behind it."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Checking what time of the day customer transact the most.\n",
        "#hour_df=df['Hour'].value_counts().reset_index()\n",
        "#hour_df.rename(columns={'index': 'Hours'}, inplace=True)\n",
        "#hour_df.rename(columns={'Hour': 'Count'}, inplace=True)\n",
        "\n",
        "# Categorizing Hour into Morning, Afternoon and Evening\n",
        "def time_type(time):\n",
        "  if(time>=6 and time<=11):\n",
        "    return 'Morning'\n",
        "  elif(time>=12 and time<=17):\n",
        "    return 'Afternoon'\n",
        "  else:\n",
        "    return 'Evening'\n",
        "\n",
        "df['Time_type']=df['Hour'].apply(time_type)\n",
        "\n",
        "#Visualizing the transactions in morning, afternoon and night\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Transaction in Hour of the day')\n",
        "sns.countplot(x = 'Time_type', data = df, palette = 'spring_r')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used barplot to show the count of sales in morning afternoon and evening time of a day."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Most number of transaction are done in afternoon, followed by morning.\n",
        "- Least number of transaction are done in Evening."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can help store to schedule there digital advertisement accordingly for better optimization."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Recency Histogram\n",
        "import math\n",
        "import scipy\n",
        "x=recency_df.Recency\n",
        "mu=np.mean(x)\n",
        "sigma=math.sqrt(np.var(x))\n",
        "n,bins,patches=plt.hist(x,1000,facecolor='blue',alpha=0.75)#alpha=transparency parameter\n",
        "# Add a best fit line\n",
        "y=scipy.stats.norm.pdf(bins,mu,sigma)#norm.pdf-probability density function for norm\n",
        "l=plt.plot(bins,y,'r--',lw=2)\n",
        "\n",
        "plt.xlabel('Recency in days')\n",
        "plt.ylabel('Number of transactions')\n",
        "plt.title('Histogram of Sales Recency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used the histogram to see the distribution of recency with respect to number of transaction."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a skewed distribution for recency showing higher transaction in recent days."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recency shows days since last purchace this information can help store to see the which customers they are about to lose and which they have lost. And thus come up with a stratergies to retain them."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Distribution Plot for frequency\n",
        "x = frequency_df['Frequency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x,color='r')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used distribution plot to check the distribution of frequency."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution is right skewed."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of perchases are between 1 to 15. Customers with higher number of purchases are loyal customer and could be included in loyalty program."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Distribution Plot for Monetary Value\n",
        "x = monetary_df['Monetary_Value']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x,color='r')"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used distribution plot to check the distribution of Monetary Value."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution is right skewed."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value ranges from 0-2000. Customer on higher end of this spectrum are premium customer."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "rfm_df.corr()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(rfm_df.corr())"
      ],
      "metadata": {
        "id": "W_mEo46_3WGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used heatmap to plot the correlation between Recency, Frequency and Monetary Value."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Recency is negatively correlated to both Frequency and Monetary value.\n",
        "- Frequency and Monetary Value are positively correlated."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "# setting the axis for graph\n",
        "sns.pairplot(rfm_df)\n",
        "# adding visualizations to chart\n",
        "plt.minorticks_on()\n",
        "plt.grid(which='both',alpha=0.3,linestyle='--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used Pair plot to understand the best set of features to explain a relationship between two variables."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of all three feature is rightly skewed."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Recency is negatively correlated to Frequency.\n",
        "\n",
        "2. Monetary Value and Frequency are positively correlated.\n",
        "\n",
        "3. Recency is negatively correlated to Monetary value."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Null Hypothesis(H0) -** There is no correlation between Recency and Frequency.\n",
        "\n",
        "- **Alternate Hypothesis(HA) -** Recency is negatively correlated to Frequency."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "group1 = rfm_df['Recency'].values\n",
        "group2 = rfm_df['Frequency'].values\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.ttest_ind(a = group1, b = group2, equal_var = False)"
      ],
      "metadata": {
        "id": "l5gf-RtEeMBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- p-value is 0.00 which is less than significance level 0.05.\n",
        "- We have enough evidence to reject the null hypothesis.\n"
      ],
      "metadata": {
        "id": "bSrZKOELfDZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have performed two sample t-test to obtain p-value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find the group means of two sample for comparision so we have used two sample t-test."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Null Hypothesis(H0) -** There is no correlation between Monetary value and Frequency.\n",
        "\n",
        "- **Alternate Hypothesis(HA) -** Monetary Value is positively correlated to Frequency."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "group3 = rfm_df['Monetary_Value'].values"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.ttest_ind(a = group3, b = group2, equal_var = False)"
      ],
      "metadata": {
        "id": "MRcllk_ZgbJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- p-value is very less than significance level 0.05.\n",
        "- We have enough evidence to reject the null hypothesis."
      ],
      "metadata": {
        "id": "auHn7aJTgi5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have performed two sample t-test to obtain p-value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to find the group means of two sample for comparision so we have used two sample t-test."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Null Hypothesis(H0) -** There is no correlation between Monetary value and Recency.\n",
        "\n",
        "- **Alternate Hypothesis(HA) -** Recency is Negatively correlated to Monetary Value."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "stats.ttest_ind(a = group1, b = group3, equal_var = False)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- p-value is less than significance level 0.05.\n",
        "- We have enough evidence to reject the null hypothesis."
      ],
      "metadata": {
        "id": "Rqrvg4HThgjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have performed two sample t-test to obtain p-value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to find the group means of two sample for comparision so we have used two sample t-test."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- There were missing values in CustomerID and Description.\n",
        "- The reason behind this could be that customer buying from the online store was not a registered customer.\n",
        "- And there is no way we can impute the CustomerID and Description as CustomerID is unique to every customer and Description is unique to every product.\n",
        "- So we dropped all the information with missing values."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "#Checking distribution for Recency, Frequency and Monetary value\n",
        "scatter_matrix(rfm_df, alpha = 0.3, figsize = (11,5), diagonal = 'kde')"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Distribution for all three features, Recency, Frequency and Monetary value are right skewed.\n",
        "- Clustering algorithms require normal distribuiton.\n",
        "- We'll convert these right skewed distribution to near normal distribution by applying log transformation."
      ],
      "metadata": {
        "id": "jZ2vDTaY58sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying log transformation\n",
        "rfm_log_R = np.log(rfm_df['Recency']+0.1) #can't take log(0) and so add a small number\n",
        "rfm_log_F = np.log(rfm_df['Frequency'])\n",
        "rfm_log_M = np.log(rfm_df['Monetary_Value']+0.1)"
      ],
      "metadata": {
        "id": "4gaQhJUx6Ae2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_df = pd.DataFrame({'Monetary_Value': rfm_log_M,'Recency': rfm_log_R,'Frequency': rfm_log_F})\n",
        "log_df.head()"
      ],
      "metadata": {
        "id": "i_6SEg9z6G9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing the distribution of Recency, Frequency and Monetary Value after log transformation\n",
        "scatter_matrix(log_df, alpha = 0.2, figsize = (11,5), diagonal = 'kde')"
      ],
      "metadata": {
        "id": "CqA1VsVY6Mkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Distribution of Monetary value is better, However the distribution of Recency and Frequency have inproved but not as much."
      ],
      "metadata": {
        "id": "s6ONUqNq6RJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_df.corr()"
      ],
      "metadata": {
        "id": "HL-eEn-m6WdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(log_df.corr())"
      ],
      "metadata": {
        "id": "qbVtR_pD6Y3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- After log transformation it can be seen that Monetary value and frequency show strong positive correlation."
      ],
      "metadata": {
        "id": "VfODNRZj6cOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - KMeans Clustering"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Elbow Method\n",
        "sse = {} #Sum Of Squared Error\n",
        "# Fit KMeans and calculate SSE for each k\n",
        "for k in range(1, 11):\n",
        "\n",
        "    # Initialize KMeans with k clusters\n",
        "    kmeans = KMeans(n_clusters=k, random_state=1)\n",
        "\n",
        "    # Fit KMeans on the normalized dataset\n",
        "    kmeans.fit(log_df)\n",
        "\n",
        "    # Assign sum of squared distances to k element of dictionary\n",
        "    sse[k] = kmeans.inertia_\n",
        "\n",
        "# Plotting the elbow plot\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('k');\n",
        "plt.ylabel('Sum of squared errors')\n",
        "sns.pointplot(x=list(sse.keys()), y=list(sse.values()))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w1LVaO667rZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "log_values = log_df.values\n",
        "wcss_silhouette = []\n",
        "for i in range(3,12):\n",
        "    km = KMeans(n_clusters=i, random_state=0,init='k-means++').fit(log_values)\n",
        "    preds = km.predict(log_values)\n",
        "    silhouette = silhouette_score(log_values,preds)\n",
        "    wcss_silhouette.append(silhouette)\n",
        "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"The silhouette coefficient method \\nfor determining number of clusters\\n\",fontsize=16)\n",
        "plt.scatter(x=[i for i in range(3,12)],y=wcss_silhouette,s=150,edgecolor='k')\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"Number of clusters\",fontsize=14)\n",
        "plt.ylabel(\"Silhouette score\",fontsize=15)\n",
        "plt.xticks([i for i in range(3,12)],fontsize=14)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "luMvL0QO04bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we can clearly see that optimum number of cluster should be 5 not 3 or 4. Because that is the only point after which the mean cluster distance looks to be plateaued after a steep downfall.\n",
        "\n",
        "- So we will assume the 5 number of clusters as best for grouping of customer segments."
      ],
      "metadata": {
        "id": "T7JGiI4_7hVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 5\n",
        "kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=30)\n",
        "kmeans.fit(log_values)\n",
        "clusters_customers = kmeans.predict(log_values)\n",
        "silhouette_avg = silhouette_score(log_values, clusters_customers)\n",
        "print('score de silhouette: {:<.3f}'.format(silhouette_avg))"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building K-means model using n_cluster = 5\n",
        "kmeans = KMeans(n_clusters = 5)\n",
        "kmeans.fit(log_values)\n",
        "y_kmeans= kmeans.predict(log_values)"
      ],
      "metadata": {
        "id": "-Mjbc1Bj74uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing Cluster\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.title('customer segmentation based on Recency, Frequency and Monetary')\n",
        "plt.scatter(log_values[:, 0], log_values[:, 1], c=y_kmeans, s=50, cmap='spring_r')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
      ],
      "metadata": {
        "id": "FNLec8Bd8YAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building K-means model using n_cluster = 4\n",
        "#kmeans3 = KMeans(n_clusters = 4)\n",
        "#kmeans3.fit(log_values)\n",
        "#y_kmeans3= kmeans3.predict(log_values)"
      ],
      "metadata": {
        "id": "2yEse1wr8eiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing Cluster\n",
        "#plt.figure(figsize=(15,10))\n",
        "#plt.title('customer segmentation based on Recency, Frequency and Monetary')\n",
        "#plt.scatter(log_values[:, 0], log_values[:, 1], c=y_kmeans3, s=50, cmap='spring_r')\n",
        "\n",
        "#centers = kmeans3.cluster_centers_\n",
        "#plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
      ],
      "metadata": {
        "id": "ZppzM_BY8h-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used silhouette score and elbow method to get the optimal number of cluster."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - DBScan Clustering"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = DBSCAN(eps=0.5, min_samples=15).fit_predict(log_values)\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(log_values[:,0], log_values[:,1], c=y_pred)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is the most well-known density-based clustering algorithm\n",
        "- Unlike k-means, DBSCAN does not require the number of clusters as a parameter. Rather it infers the number of clusters based on the data, and it can discover clusters of arbitrary shape (for comparison, k-means usually discovers spherical clusters).\n",
        "- DBSCAN categories the data points into three categories\n",
        "  - Core Points - (Steel blue points in scatter plot)\n",
        "  - Border Points - (Green points in scatter plot)\n",
        "  - Outliers - (Dark Blue points in scatterplot)\n",
        "- (As we can see from the DBscan Visualization)"
      ],
      "metadata": {
        "id": "IFFNrdlJ3tgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 - Hierarchical Clustering"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the dendogram to find the optimal number of clusters\n",
        "plt.figure(figsize=(13,8))\n",
        "dendrogram = sch.dendrogram(sch.linkage(log_values, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Customers')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Optimal number of cluster is 3 as per the dendogram."
      ],
      "metadata": {
        "id": "0nkkzHQ09YR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agglomerative clustering for n_cluster = 2\n",
        "#from sklearn.cluster import AgglomerativeClustering\n",
        "#hc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
        "#y_hc = hc.fit_predict(log_values)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the clusters\n",
        "#plt.figure(figsize=(13,8))\n",
        "#plt.scatter(log_values[y_hc == 0, 0], log_values[y_hc == 0, 1], s = 100, c = 'red', label = 'Customer Type 1')\n",
        "#plt.scatter(log_values[y_hc == 1, 0], log_values[y_hc == 1, 1], s = 100, c = 'blue', label = 'Customer Type 2')\n",
        "\n",
        "#plt.title('Clusters')\n",
        "#plt.xlabel('RFM')\n",
        "\n",
        "#plt.ylabel('Spending Score')\n",
        "#plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "5MIbpigj9ihu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agglomerative clustering for n_cluster = 3\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc3 = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')\n",
        "y_hc3 = hc3.fit_predict(log_values)"
      ],
      "metadata": {
        "id": "rf_7Yag55m9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(log_values[y_hc3 == 0, 0], log_values[y_hc3 == 0, 1], s = 100, c = 'red', label = 'Customer Type 1')\n",
        "plt.scatter(log_values[y_hc3 == 1, 0], log_values[y_hc3 == 1, 1], s = 100, c = 'blue', label = 'Customer Type 2')\n",
        "plt.scatter(log_values[y_hc3 == 2, 0], log_values[y_hc3 == 2, 1], s = 100, c = 'green', label = 'Customer Type 3')\n",
        "\n",
        "plt.title('Clusters')\n",
        "plt.xlabel('RFM')\n",
        "\n",
        "plt.ylabel('Spending Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AfWSRMOD5wX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Customer Segmentation**"
      ],
      "metadata": {
        "id": "MbvHDoI-cJYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_df1 = log_df.rename(columns = {'Recency' : 'Log_R', 'Frequency' : 'Log_F', 'Monetary_Value' : 'Log_M'})\n",
        "log_df1.head()"
      ],
      "metadata": {
        "id": "KHT1gqAL95k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_data = rfm_segment.merge(right=log_df1, on=\"CustomerID\", how=\"left\")\n",
        "rfm_data.head()"
      ],
      "metadata": {
        "id": "I1HoGDa8-AEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_data['Cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "Xr3jt0CP-C7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_data.head(10)"
      ],
      "metadata": {
        "id": "kjSW3jY2-Iw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = list(rfm_data.columns)\n",
        "columns.remove('Segment')\n",
        "columns.append('Segment')\n",
        "rfm_data = rfm_data[columns]"
      ],
      "metadata": {
        "id": "XP_ihDZqFcRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_data.head()"
      ],
      "metadata": {
        "id": "zPgqTm9mFrRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_data['Cluster'].value_counts()"
      ],
      "metadata": {
        "id": "x9LxosDj-h2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's check mean values of the cluster for recency, frequnecy and monetary\n",
        "rfm_data.groupby('Cluster').agg({'Recency':'mean',\n",
        "                               'Frequency':'mean',\n",
        "                               'Monetary_Value':'mean'})"
      ],
      "metadata": {
        "id": "YO1qm6LD-Ok7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_data.sample(10)\n",
        "print (\"Platinum customers belong to cluster                      : {} \".format(rfm_data[rfm_data['Segment']=='Platinum Customers']['Cluster'].unique()))\n",
        "print (\"Big Spenders belong to cluster                            : {} \".format(rfm_data[rfm_data['Segment']=='Big Spenders']['Cluster'].unique()))\n",
        "print (\"High Spend new Customers belong to cluster                : {} \".format(rfm_data[rfm_data['Segment']=='High Spend New Customers']['Cluster'].unique()))\n",
        "print (\"Lowest-Spending Active Loyal Customers belong to cluster  : {} \".format(rfm_data[rfm_data['Segment']=='Lowest-Spending Active Loyal Customers']['Cluster'].unique()))\n",
        "print (\"Recent Customers belong to cluster                        : {} \".format(rfm_data[rfm_data['Segment']=='Recent Customers']['Cluster'].unique()))\n",
        "print (\"Good Customers Almost Lost belong to cluster              : {} \".format(rfm_data[rfm_data['Segment']=='Good Customers Almost Lost']['Cluster'].unique()))\n",
        "print (\"Churned Best Customers belong to cluster                  : {} \".format(rfm_data[rfm_data['Segment']=='Churned Best Customers']['Cluster'].unique()))\n",
        "print (\"Lost Cheap customers belong to cluster                    : {} \".format(rfm_data[rfm_data['Segment']=='Lost Cheap Customers ']['Cluster'].unique()))\n"
      ],
      "metadata": {
        "id": "EUCT3DbI-6iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis Customer in each cluster**"
      ],
      "metadata": {
        "id": "7ihp4yT5F4Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for cluster - 0\n",
        "rfm_data[rfm_data.Cluster == 0].sample(5)"
      ],
      "metadata": {
        "id": "jsvxxViJFznE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Customer belonging to cluster 0 have lowest RFM value and RFM Score and they belong to Lost Cheap Customer segment."
      ],
      "metadata": {
        "id": "n3iBtk1aGSRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for cluster - 1\n",
        "rfm_data[rfm_data.Cluster == 1].sample(5)"
      ],
      "metadata": {
        "id": "t67PNMtyGmeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Customer belonging to cluster 1 have high recency value and low monetary and frequency value and most of them fall into Lowest-Spending Active Loyal Customer and Recent Customer segments."
      ],
      "metadata": {
        "id": "CztjTeL-G1sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for cluster - 2\n",
        "rfm_data[rfm_data.Cluster == 2].sample(5)"
      ],
      "metadata": {
        "id": "KvjMXHOQHLYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Customer belonging to cluster 2 shows the same charecteristics as customer in cluster 0, with low RFM value and RFM score, and they also belong to Lost Cheap Customer and others segments."
      ],
      "metadata": {
        "id": "59AA7VhpHbPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for cluster - 3\n",
        "rfm_data[rfm_data.Cluster == 3].sample(5)"
      ],
      "metadata": {
        "id": "RjJckMaGH23R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Customer belonging to cluster 3 have very high RFM value and RMF score, most of the customer belong to Platinum Customer segment and some to Big Spenders segment."
      ],
      "metadata": {
        "id": "nmrahlEaH7wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for cluster - 4\n",
        "rfm_data[rfm_data.Cluster == 4].sample(5)"
      ],
      "metadata": {
        "id": "1Ai8qG6FISkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Customer belonging to cluster 4 have good RFM value and RFM score, most of the customer belong to Platinum Customer and Big Spender segments and some also belong to Recent Customer with high Monetary Value."
      ],
      "metadata": {
        "id": "I_hG0yspIbOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Customer are segmented in 5 different clusters.\n",
        "\n",
        "- Customer belonging to cluster 0 have lowest RFM value and RFM Score and they belong to Lost Cheap Customer segment.\n",
        "\n",
        "- Customer belonging to cluster 1 have high recency value and low monetary and frequency value and most of them fall into Lowest-Spending Active Loyal Customer and Recent Customer segments.\n",
        "\n",
        "- Customer belonging to cluster 2 shows the same charecteristics as customer in cluster 0, with low RFM value and RFM score, and they also belong to Lost Cheap Customer and others segments.\n",
        "\n",
        "- Customer belonging to cluster 3 have very high RFM value and RMF score, most of the customer belong to Platinum Customer segment and some to Big Spenders segment.\n",
        "\n",
        "- Customer belonging to cluster 4 have good RFM value and RFM score, most of the customer belong to Platinum Customer and Big Spender segments and some also belong to Recent Customer with high Monetary Value."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}